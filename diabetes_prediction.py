# -*- coding: utf-8 -*-
"""Diabetes Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lx4-z3fTns2OzqOvriEjooGlC7AlicrX

# Diabetes Prediction: Understanding Features Through Visualization

Welcome! Today we'll explore a real medical dataset and understand what makes someone at risk for diabetes.
We'll use the famous **Pima Indians Diabetes Database** - real clinical data used in medical research.

**What we'll learn:**
- What features (medical measurements) matter for diabetes prediction
- How to visualize data to spot patterns
- Why understanding your data is crucial before building any model

## Step 1: Installing our toolkit
- **pandas**: Read and manipulate data tables
- **numpy**: Fast number calculations
- **matplotlib & seaborn**: Create beautiful visualizations
- **scikit-learn**: Tools for building ML models
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
import warnings
warnings.filterwarnings('ignore')

# Set visualization style
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)

"""## Step 2: Loading the Pima Indians Diabetes Dataset
This dataset contains health measurements from 768 women of Pima Indian heritage.
Each row represents one person, with their medical measurements and diabetes status.

**Features:**
- Pregnancies: Number of pregnancies
- Glucose: Blood glucose level (mg/dL) - **Key diabetes indicator**
- BloodPressure: Diastolic blood pressure (mm Hg)
- SkinThickness: Triceps skin fold thickness (mm)
- Insulin: 2-Hour serum insulin (mu U/ml)
- BMI: Body mass index (weight in kg/(height in m)^2)
- DiabetesPedigreeFunction: Genetic likelihood score
- Age: Age in years
- Outcome: 0 = No diabetes, 1 = Diabetes

"""

# Load data
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
column_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',
                'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']
df = pd.read_csv(url, names=column_names)

# Display first few rows
print("Dataset Preview:")
#display(df.head(10))

print(f"\nDataset Shape: {df.shape[0]} patients, {df.shape[1]} columns")
print(f"\nBasic Statistics:")
#display(df.describe())

"""## Step 3: Class Distribution - How balanced is our data?
Let's see how many people have diabetes vs. don't have diabetes.
This is crucial because imbalanced data affects model training!

"""

outcome_counts = df['Outcome'].value_counts()
print(f"No Diabetes (0): {outcome_counts[0]} ({outcome_counts[0]/len(df)*100:.1f}%)")
print(f"Diabetes (1): {outcome_counts[1]} ({outcome_counts[1]/len(df)*100:.1f}%)")

# Visualize
plt.figure(figsize=(8, 5))
sns.countplot(data=df, x='Outcome', palette='Set2')
plt.title('Diabetes vs No Diabetes', fontsize=14, fontweight='bold')
plt.xlabel('Outcome (0=No Diabetes, 1=Diabetes)')
plt.ylabel('Number of Patients')
plt.xticks([0, 1], ['No Diabetes', 'Diabetes'])
plt.show()

"""## Step 4: How do features differ between diabetic and non-diabetic patients?
Let's visualize key medical measurements and spot patterns.
"""

fig, axes = plt.subplots(2, 4, figsize=(16, 8))
features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',
            'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']

for idx, feature in enumerate(features):
    row, col = idx // 4, idx % 4
    sns.histplot(data=df, x=feature, hue='Outcome', kde=True, ax=axes[row, col], palette='Set1')
    axes[row, col].set_title(f'{feature} Distribution')
    axes[row, col].legend(['No Diabetes', 'Diabetes'])

plt.tight_layout()
plt.show()

print(" Key Observations:")
print("- Higher glucose levels strongly correlate with diabetes")
print("- BMI and age also show clear differences")
print("- Some features have zeros (missing data) - we'll handle this!")

"""## Step 5: Which features are most related to diabetes?
Correlation shows how strongly features relate to each other and to diabetes.
"""

plt.figure(figsize=(10, 8))
correlation = df.corr()
sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', center=0)
plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')
plt.show()

print(" Correlation with Diabetes (Outcome):")
correlations_with_outcome = correlation['Outcome'].sort_values(ascending=False)
print(correlations_with_outcome)

"""## Step 6: Data Quality Check
Medical measurements can't be zero (glucose=0 means... dead!)
Let's identify and handle these missing values properly.
"""

# Features that shouldn't be zero
zero_features = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']

print("Missing Values (recorded as 0):")
for feature in zero_features:
    zero_count = (df[feature] == 0).sum()
    print(f"{feature}: {zero_count} zeros ({zero_count/len(df)*100:.1f}%)")

# Replace zeros with median (grouped by outcome for better imputation)
df_clean = df.copy()
for feature in zero_features:
    df_clean[feature] = df_clean.groupby('Outcome')[feature].transform(
        lambda x: x.replace(0, x.median())
    )

print("\n Cleaned dataset ready!")

"""## Step 7: Quick peek - which features matter most?
We'll train a simple model just to see feature importance rankings.

"""

X = df_clean.drop('Outcome', axis=1)
y = df_clean['Outcome']

# Quick Random Forest for feature importance
rf_quick = RandomForestClassifier(n_estimators=100, random_state=42)
rf_quick.fit(X, y)

# Plot feature importance
feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': rf_quick.feature_importances_
}).sort_values('Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')
plt.title('Feature Importance for Diabetes Prediction', fontsize=14, fontweight='bold')
plt.xlabel('Importance Score')
plt.show()

print(" Top 3 Most Important Features:")
print(feature_importance.head(3))

"""## Step 8: Preparing for Day 6
We'll save this cleaned dataset so we can use it tomorrow for model building!
"""

df_clean.to_csv('diabetes_cleaned.csv', index=False)
print(" Clean data saved as 'diabetes_cleaned.csv'")
print("\n Day 5 Summary:")
print("- Explored 768 patient records with 8 medical features")
print("- Identified key patterns: Glucose, BMI, and Age are strong indicators")
print("- Handled missing values properly")
print("- Ready to build our prediction model tomorrow!")